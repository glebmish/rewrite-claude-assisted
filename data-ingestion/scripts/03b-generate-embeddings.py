#!/usr/bin/env python3
"""
Script: 03b-generate-embeddings.py
Purpose: Generate semantic embeddings for recipes from structured metadata

This script:
1. Reads recipe metadata from JSON (generated by 02b-generate-structured-data.sh)
2. Creates structured embedding text for each recipe
3. Generates embeddings using sentence-transformers
4. Stores embeddings and metadata in PostgreSQL

Note: This script expects:
- PostgreSQL database running with schema initialized
- Recipes already ingested by 03-ingest-docs.py
- Recipe metadata JSON file generated by 02b-generate-structured-data.sh
"""

import asyncio
import asyncpg
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Optional
from dotenv import load_dotenv
from tqdm import tqdm

# Import sentence transformers (will be installed via requirements.txt)
try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    print("Error: sentence-transformers not installed.", file=sys.stderr)
    print("Install with: pip install sentence-transformers", file=sys.stderr)
    sys.exit(1)

# Configuration
SCRIPT_DIR = Path(__file__).parent
PROJECT_DIR = SCRIPT_DIR.parent

# Load environment variables
load_dotenv(PROJECT_DIR / '.env')

# Database configuration
DB_HOST = os.getenv('DB_HOST', 'localhost')
DB_PORT = int(os.getenv('DB_PORT', '5432'))
DB_NAME = os.getenv('DB_NAME', 'openrewrite_recipes')
DB_USER = os.getenv('DB_USER', 'mcp_user')
DB_PASSWORD = os.getenv('DB_PASSWORD', 'changeme')

# Embedding model configuration
EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL', 'all-MiniLM-L6-v2')
EMBEDDING_DIMENSION = int(os.getenv('EMBEDDING_DIMENSION', '384'))

# Generator configuration
GENERATOR_WORKSPACE = str(PROJECT_DIR / 'workspace')
GENERATOR_OUTPUT_DIR = 'build/docs'
GENERATOR_DIR = Path(GENERATOR_WORKSPACE) / 'rewrite-recipe-markdown-generator'
METADATA_FILE = GENERATOR_DIR / GENERATOR_OUTPUT_DIR / 'recipe-metadata.json'

# Verbose mode
VERBOSE = os.getenv('VERBOSE', 'false').lower() == 'true'


def log(message: str, force: bool = False):
    """Log message if verbose mode is enabled or force is True."""
    if VERBOSE or force:
        print(message, file=sys.stderr)


def create_embedding_text(metadata: Dict) -> str:
    """
    Create structured text for embedding from recipe metadata.

    Format:
        Recipe: [displayName or name]
        Description: [description]
        Tags: [comma-separated tags]
        Full name: [fully qualified name]

    Args:
        metadata: Recipe metadata dictionary

    Returns:
        Structured text suitable for embedding
    """
    name = metadata.get('name', '')
    display_name = metadata.get('displayName') or name.split('.')[-1]
    description = metadata.get('description', '')
    tags = metadata.get('tags', [])

    # Build structured text
    parts = [
        f"Recipe: {display_name}",
    ]

    if description:
        parts.append(f"Description: {description}")

    if tags:
        parts.append(f"Tags: {', '.join(tags)}")

    parts.append(f"Full name: {name}")

    return '\n'.join(parts)


async def get_recipe_id(conn: asyncpg.Connection, recipe_name: str) -> Optional[int]:
    """
    Get recipe_id for a given recipe name.

    Args:
        conn: Database connection
        recipe_name: Fully qualified recipe name

    Returns:
        Recipe ID if found, None otherwise
    """
    row = await conn.fetchrow(
        "SELECT id FROM recipes WHERE recipe_name = $1",
        recipe_name
    )
    return row['id'] if row else None


async def upsert_recipe_metadata(
    conn: asyncpg.Connection,
    recipe_id: int,
    metadata: Dict
):
    """
    Insert or update recipe metadata in the database.

    Args:
        conn: Database connection
        recipe_id: Recipe ID
        metadata: Recipe metadata dictionary
    """
    await conn.execute("""
        INSERT INTO recipe_metadata (
            recipe_id, display_name, description, tags,
            is_composite, recipe_count, updated_at
        ) VALUES ($1, $2, $3, $4, $5, $6, NOW())
        ON CONFLICT (recipe_id) DO UPDATE SET
            display_name = EXCLUDED.display_name,
            description = EXCLUDED.description,
            tags = EXCLUDED.tags,
            is_composite = EXCLUDED.is_composite,
            recipe_count = EXCLUDED.recipe_count,
            updated_at = NOW()
    """,
        recipe_id,
        metadata.get('displayName'),
        metadata.get('description'),
        metadata.get('tags', []),
        metadata.get('isComposite', False),
        metadata.get('recipeCount', 0)
    )


async def upsert_recipe_embedding(
    conn: asyncpg.Connection,
    recipe_id: int,
    embedding: List[float],
    model_name: str
):
    """
    Insert or update recipe embedding in the database.

    Args:
        conn: Database connection
        recipe_id: Recipe ID
        embedding: Embedding vector
        model_name: Name of the embedding model
    """
    # Convert embedding to PostgreSQL vector format
    embedding_str = '[' + ','.join(str(x) for x in embedding) + ']'

    await conn.execute("""
        INSERT INTO recipe_embeddings (
            recipe_id, embedding, embedding_model
        ) VALUES ($1, $2::vector, $3)
        ON CONFLICT (recipe_id, embedding_model) DO UPDATE SET
            embedding = EXCLUDED.embedding,
            created_at = NOW()
    """,
        recipe_id,
        embedding_str,
        model_name
    )


async def process_recipes(metadata_list: List[Dict], model: SentenceTransformer):
    """
    Process all recipes: generate embeddings and store in database.

    Args:
        metadata_list: List of recipe metadata dictionaries
        model: Loaded sentence transformer model
    """
    # Connect to database
    log(f"→ Connecting to database at {DB_HOST}:{DB_PORT}/{DB_NAME}...", force=True)
    conn = await asyncpg.connect(
        host=DB_HOST,
        port=DB_PORT,
        database=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD
    )

    try:
        log(f"✓ Connected to database", force=True)

        # Verify pgvector extension is installed
        log(f"→ Verifying pgvector extension...", force=True)
        try:
            vector_version = await conn.fetchval("SELECT extversion FROM pg_extension WHERE extname = 'vector'")
            if vector_version:
                log(f"✓ pgvector extension installed (version: {vector_version})", force=True)
            else:
                log(f"✗ ERROR: pgvector extension not found!", force=True)
                log(f"  Run 00-init-database.sh to initialize the database with pgvector", force=True)
                return
        except Exception as e:
            log(f"✗ ERROR checking pgvector extension: {e}", force=True)
            return

        log("", force=True)

        # Statistics
        processed = 0
        skipped = 0
        errors = 0

        # Process each recipe
        log(f"→ Processing {len(metadata_list)} recipes...", force=True)
        with tqdm(total=len(metadata_list), desc="Generating embeddings", unit="recipe") as pbar:
            for metadata in metadata_list:
                recipe_name = metadata.get('name')
                if not recipe_name:
                    log(f"  Warning: Skipping recipe with no name: {metadata}", force=VERBOSE)
                    skipped += 1
                    pbar.update(1)
                    continue

                try:
                    # Get recipe_id
                    recipe_id = await get_recipe_id(conn, recipe_name)
                    if recipe_id is None:
                        log(f"  Warning: Recipe not found in database: {recipe_name}", force=VERBOSE)
                        skipped += 1
                        pbar.update(1)
                        continue

                    # Store metadata
                    try:
                        await upsert_recipe_metadata(conn, recipe_id, metadata)
                    except Exception as e:
                        log(f"  ✗ Error storing metadata for {recipe_name}: {e}", force=True)
                        raise

                    # Create embedding text
                    embedding_text = create_embedding_text(metadata)

                    # Generate embedding
                    embedding = model.encode(embedding_text, show_progress_bar=False)

                    # Verify embedding dimension matches expected dimension
                    if len(embedding) != EMBEDDING_DIMENSION:
                        raise ValueError(f"Embedding dimension mismatch: expected {EMBEDDING_DIMENSION}, got {len(embedding)}")

                    # Store embedding with better error handling
                    try:
                        await upsert_recipe_embedding(
                            conn,
                            recipe_id,
                            embedding.tolist(),
                            EMBEDDING_MODEL
                        )
                        log(f"  ✓ Stored embedding for: {recipe_name}", force=VERBOSE)
                    except Exception as e:
                        log(f"  ✗ Error storing embedding for {recipe_name}: {type(e).__name__}: {e}", force=True)
                        raise

                    processed += 1
                    log(f"  ✓ Processed: {recipe_name}", force=VERBOSE)

                except Exception as e:
                    log(f"  ✗ Error processing {recipe_name}: {type(e).__name__}: {e}", force=True)
                    import traceback
                    log(f"  Traceback: {traceback.format_exc()}", force=VERBOSE)
                    errors += 1

                pbar.update(1)

        log("", force=True)
        log("========================================", force=True)
        log("Summary", force=True)
        log("========================================", force=True)
        log(f"Successfully processed: {processed}", force=True)
        log(f"Skipped (not in DB): {skipped}", force=True)
        log(f"Errors: {errors}", force=True)
        log(f"Total: {len(metadata_list)}", force=True)

        # Verify embeddings were inserted
        log("", force=True)
        log("→ Verifying embeddings in database...", force=True)
        try:
            embedding_count = await conn.fetchval(
                "SELECT COUNT(*) FROM recipe_embeddings WHERE embedding_model = $1",
                EMBEDDING_MODEL
            )
            log(f"✓ Embeddings in database for model '{EMBEDDING_MODEL}': {embedding_count}", force=True)

            if embedding_count == 0 and processed > 0:
                log(f"⚠ WARNING: Processed {processed} recipes but no embeddings found in database!", force=True)
                log(f"  This suggests embeddings are not being inserted properly.", force=True)
        except Exception as e:
            log(f"✗ Error verifying embeddings: {e}", force=True)

    finally:
        await conn.close()


async def main():
    """Main function."""
    log("========================================", force=True)
    log("Stage 3b: Generate Recipe Embeddings", force=True)
    log("========================================", force=True)
    log("", force=True)

    # Check if metadata file exists
    if not METADATA_FILE.exists():
        print(f"✗ Error: Metadata file not found: {METADATA_FILE}", file=sys.stderr)
        print(f"  Run 02b-generate-structured-data.sh first", file=sys.stderr)
        sys.exit(1)

    log(f"✓ Found metadata file: {METADATA_FILE}", force=True)

    # Load metadata
    log(f"→ Loading recipe metadata...", force=True)
    with open(METADATA_FILE, 'r') as f:
        metadata_list = json.load(f)

    log(f"✓ Loaded {len(metadata_list)} recipes", force=True)
    log("", force=True)

    # Load embedding model
    log(f"→ Loading embedding model: {EMBEDDING_MODEL}...", force=True)
    log(f"  (First run will download model, subsequent runs use cache)", force=True)
    model = SentenceTransformer(EMBEDDING_MODEL)
    log(f"✓ Model loaded (dimension: {EMBEDDING_DIMENSION})", force=True)
    log("", force=True)

    # Process recipes
    await process_recipes(metadata_list, model)

    log("", force=True)
    log("✓ Stage 3b Complete", force=True)
    log("", force=True)


if __name__ == '__main__':
    asyncio.run(main())
